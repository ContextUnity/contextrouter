[project]
name = "contextrouter"
version = "0.13.1"
description = "Modular LangGraph-powered agentic brain for multi-source knowledge orchestration and RAG"
readme = "README.md"
requires-python = ">=3.13"
authors = [
    { name = "Pylypchuk Oleksii", email = "oleksii.pylypchuk@tuta.com" },
]
license = { file = "LICENSE.md" }
classifiers = [
    "Development Status :: 3 - Alpha",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3 :: Only",
    "Programming Language :: Python :: 3.13",
    "Typing :: Typed",
]
dependencies = [
    "python-dotenv>=1.0.0",
    "langgraph>=0.2.0",
    "langchain-core>=0.3.0",
    "langchain-community>=0.3.0",
    "pydantic>=2.0.0",
    "click>=8.0.0",
    "typer>=0.12.0",
    "rich>=13.0.0",
    "tomli>=2.0.0",
    "storage>=0.0.4.3",
    "language-tool-python>=3.2.2",
]

[project.urls]
Homepage = "https://contextrouter.dev"
Documentation = "https://contextrouter.dev"
Repository = "https://github.com/ContextUnity/contextrouter"
Issues = "https://github.com/ContextUnity/contextrouter/issues"

[project.optional-dependencies]
dev = [
    "pre-commit>=3.0.0",
    "ruff>=0.14.0",
    "pytest>=8.0.0",
    "joblib>=1.4.0",
    "alembic>=1.13.0",
    "twine>=5.0.0",
    "build>=1.0.0",
]
# Core providers (most common)
vertex = [
    "langchain-google-vertexai>=2.0.0",
    "langchain-google-genai>=2.0.0",
    "langchain-google-community>=2.0.0",
    "google-cloud-discoveryengine>=0.13.0",
    "google-cloud-aiplatform>=1.0.0",  # For Vertex AI Search
    "google-genai>=1.0.0",  # Modern SDK for native grounding (replaces deprecated vertexai.generative_models)
]
# Extended providers
storage = [
    "google-cloud-storage>=3.0.0",
    "google-cloud-firestore>=2.16.0",
    "psycopg[binary]>=3.1.0",
    "psycopg-pool>=3.2.0",
    "sqlalchemy>=2.0.0",
]
# Transport integrations
integrations = [
    "python-telegram-bot>=21.0",
    "google-api-python-client>=2.100.0,<3.0.0",
    "google-auth>=2.25.0,<3.0.0",
    "google-auth-oauthlib>=1.2.0,<2.0.0",
]
# Ingestion capabilities moved to ContextBrain
# Observability
observability = [
    "langfuse>=2.0.0",
    "opentelemetry-instrumentation-threading>=0.48b0",
]
# Alternative LLM providers
models-openai = [
    "langchain-openai>=0.1.0",
]
models-anthropic = [
    "langchain-anthropic>=0.1.0",
]
models-hf-hub = [
    "huggingface-hub>=0.20.0",
]
# Convenience bundle (all non-Vertex LLM providers we ship today)
models = [
    "contextrouter[models-openai,models-anthropic,models-hf-hub]",
]
# CPU-only local inference (heavy dependencies, development only)
hf-transformers = [
    "transformers>=4.30.0",
    "torch>=2.0.0",
]
# Local embeddings via sentence-transformers
hf-embeddings = [
    "sentence-transformers>=3.0.0",
]
# Everything (for development/testing)
all = [
    "contextrouter[vertex,integrations,observability]"
]

# Experimental / optional bundle (may be unsatisfiable depending on resolver + platform)
all_experimental = [
    "contextrouter[all]"
]
# Recursive Language Models for massive context processing (50k+ items)
# Used for deep product matching, bulk taxonomy classification
# Ref: https://arxiv.org/abs/2512.24601
# NOTE: Not yet on PyPI, install from GitHub via `uv add contextrouter[rlm]`
rlm = [
    "rlm",
]

[project.scripts]
contextrouter = "contextrouter.cli.app:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
# Allow Git-based dependencies in optional-dependencies (needed for RLM which is not on PyPI)
allow-direct-references = true

[tool.hatch.build.targets.wheel]
packages = ["src/contextrouter"]

[tool.ruff]
target-version = "py313"
line-length = 100

[tool.ruff.lint]
select = ["E", "F", "W", "I"]
ignore = ["E501"]

[dependency-groups]
dev = [
    "bandit>=1.9.2",
    "pre-commit>=4.5.1",
    "pytest>=8.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.0.0",
    "ruff>=0.14.0",
    "alembic>=1.13.0",
    "joblib>=1.4.0",
    "psycopg[binary]>=3.1.0",
    "psycopg-pool>=3.2.0",
    "contextcore",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--strict-markers",
    "--tb=short",
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "slow: Slow running tests",
]

[tool.uv.sources]
contextcore = { path = "../contextcore" }
rlm = { git = "https://github.com/alexzhang13/rlm.git" }
