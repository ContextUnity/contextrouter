# =============================================================================
# ContextRouter Environment Configuration
# =============================================================================
# Copy to `.env` and fill in your values.

# ===== Core =====
CONTEXTROUTER_DEBUG=false
CONTEXTROUTER_LOG_LEVEL=INFO
# CONTEXTROUTER_CORE_CONFIG_PATH=settings.toml

# ===== Project Configuration =====
# PROJECTS_DIR=/home/user/projects
# DEFAULT_PROJECT=traverse

# ===== Brain / Storage Delegation =====
BRAIN_MODE=grpc
# Options: grpc (network call) or local (library import)
BRAIN_GRPC_ENDPOINT=localhost:50051

# ===== Model Selection =====
CONTEXTROUTER_DEFAULT_LLM=vertex/gemini-2.5-flash
# CONTEXTROUTER_INTENT_LLM=vertex/gemini-2.5-flash-lite
# CONTEXTROUTER_GENERATION_LLM=vertex/gemini-2.5-flash
# CONTEXTROUTER_SUGGESTIONS_LLM=vertex/gemini-2.5-flash
# CONTEXTROUTER_NO_RESULTS_LLM=vertex/gemini-2.5-flash
# CONTEXTROUTER_FALLBACK_LLMS=anthropic/claude-sonnet-4,openai/gpt-5-mini

# ===== Vertex AI / Google Cloud =====
VERTEX_PROJECT_ID=your-project-id
VERTEX_LOCATION=us-central1
# VERTEX_DISCOVERY_ENGINE_LOCATION=global
# VERTEX_DATA_STORE_LOCATION=global
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json

# ===== External LLM Providers (optional) =====
# OPENAI_API_KEY=sk-...
# OPENAI_REASONING_EFFORT=medium        # minimal, low, medium, high
# ANTHROPIC_API_KEY=sk-ant-...
# PERPLEXITY_API_KEY=pplx-...
# SERPER_API_KEY=...
# GROQ_API_KEY=gsk_...
# OPENROUTER_API_KEY=sk-or-...
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# RUNPOD_API_KEY=...
# HF_TOKEN=hf_...

# ===== Local LLM (vLLM / Ollama) =====
# LOCAL_OLLAMA_BASE_URL=http://localhost:11434
# LOCAL_VLLM_BASE_URL=http://localhost:8000

# ===== Google CSE (optional) =====
# GOOGLE_CSE_ENABLED=false
# GOOGLE_CSE_API_KEY=
# GOOGLE_CSE_CX=

# ===== RAG Orchestration =====
# RAG_PROVIDER=brain
# RAG_TENANT_ID=default
# RAG_KG_BACKEND=postgres
# RAG_DB_NAME=
# DATA_STORE_ID_BLUE=
# DATA_STORE_ID_GREEN=

# ===== RAG Tuning (optional) =====
# RAG_CANDIDATE_K=20
# RAG_FINAL_K=5
# RAG_ENABLE_FTS=true
# RAG_HYBRID_VECTOR_WEIGHT=0.7
# RAG_HYBRID_TEXT_WEIGHT=0.3
# RAG_HYBRID_FUSION=rrf
# RAG_RRF_K=60
# RAG_EMBEDDINGS_MODEL=text-embedding-3-small
# RAG_MMR_ENABLED=false
# RAG_MMR_LAMBDA=0.5
# RAG_RERANK_PROVIDER=vertex
# RANKER_MODEL=semantic-ranker-512@latest
# RERANKING_ENABLED=true
# RAG_BACKEND=brain
# RAG_DUAL_READ_ENABLED=false
# RAG_DUAL_READ_SHADOW_BACKEND=vertex

# ===== RAG Source Limits (optional) =====
# MAX_BOOKS=5
# MAX_VIDEOS=3
# MAX_QA=5
# MAX_KNOWLEDGE=5
# CITATIONS_BOOKS=3
# CITATIONS_VIDEOS=2
# CITATIONS_QA=3
# CITATIONS_WEB=3
# GENERAL_RETRIEVAL_ENABLED=true
# GENERAL_RETRIEVAL_INITIAL_COUNT=20
# GENERAL_RETRIEVAL_FINAL_COUNT=5

# ===== News Engine (optional) =====
# NEWS_ENGINE_LANGUAGE_TOOL_ENABLED=false
# NEWS_ENGINE_LANGUAGE_TOOL_LANG=uk
# NEWS_ENGINE_LANGUAGE_TOOL_AUTO_CORRECT=false
# NEWS_ENGINE_DEDUPE_THRESHOLD=0.85

# ===== Enrichment Queue (Redis) =====
# ENRICHMENT_QUEUE_PREFIX=enrichment:
# ENRICHMENT_BATCH_SIZE=50

# ===== Security =====
# CONTEXTROUTER_SECURITY_ENABLED=true     # Enabled by default in Router
# CONTEXTROUTER_PRIVATE_KEY_PATH=/path/to/private.pem

# ===== Redis =====
REDIS_URL=redis://localhost:6379/0
# Alternative granular config:
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# ===== Postgres (direct, for local mode) =====
# POSTGRES_DSN=postgresql+psycopg://user:pass@localhost:5432/brain
# PGVECTOR_DIM=768
# POSTGRES_POOL_MIN_SIZE=2
# POSTGRES_POOL_MAX_SIZE=10
# POSTGRES_RLS_ENABLED=false

# ===== Observability =====
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_ENVIRONMENT=development
# LANGFUSE_SERVICE_NAME=contextrouter

# ===== Debug =====
# DEBUG_PIPELINE=false
