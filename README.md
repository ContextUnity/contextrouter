# ContextRouter

[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE.md)
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/orchestration-LangGraph-orange.svg)](https://github.com/langchain-ai/langgraph)
[![GitHub](https://img.shields.io/badge/GitHub-ContextUnity-black.svg)](https://github.com/ContextUnity/contextrouter)
[![Docs](https://img.shields.io/badge/docs-contextrouter.dev-green.svg)](https://contextrouter.dev)

> ‚ö†Ô∏è **Early Version**: This is an early version of ContextRouter. Documentation is actively being developed, and the API may change.

## What is ContextRouter?

ContextRouter is the **AI Gateway and Agent Orchestration** layer of the [ContextUnity](https://github.com/ContextUnity) ecosystem. It's built on LangGraph and provides:

- **LLM Provider Routing** ‚Äî OpenAI, Anthropic, Vertex AI, Groq, Perplexity, local models
- **Agent Orchestration** ‚Äî LangGraph state machines for complex workflows
- **Fallback & Reliability** ‚Äî automatic provider fallback with quota/rate limit handling
- **ContextUnit Protocol** ‚Äî all data flows through the provenance-tracking ContextUnit format
- **Tool Integration** ‚Äî exposes Brain (search) and Commerce (products) as LLM tools

Think of it as the **"Mind"** that processes requests, delegates memory to Brain, and orchestrates multi-step reasoning.

## Core Concepts

### ContextUnit ‚Äî The Atomic Unit

All data flowing through ContextRouter uses the **ContextUnit** protocol from [ContextCore](https://github.com/ContextUnity/contextcore):

```python
from contextcore import ContextUnit, ContextToken

unit = ContextUnit(
    payload={"query": "What is RAG?"},
    provenance=["connector:telegram", "graph:rag"],
    security=SecurityScopes(read=["knowledge:read"])
)

# Authorization via capability-based tokens
token = ContextToken(permissions=("knowledge:read",))
if token.can_read(unit.security):
    # Process request
```

Every transformation adds to the provenance chain, enabling full traceability.

### Model Registry

All LLM usage goes through the central registry with automatic fallback:

```python
from contextrouter.modules.models import model_registry

model = model_registry.get_llm_with_fallback(
    key="openai/gpt-5-mini",
    fallback_keys=["anthropic/claude-sonnet-4", "vertex/gemini-2.5-flash"],
    strategy="fallback",
    config=config,
)

response = await model.generate(request)
```

## Integration with ContextUnity

ContextRouter is the orchestration layer that connects all ContextUnity services:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         ContextRouter                               ‚îÇ
‚îÇ                     (The "Mind" ‚Äî Orchestration)                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Receives requests from protocols (Telegram, Web, API)            ‚îÇ
‚îÇ  ‚Ä¢ Routes to appropriate LLM providers                              ‚îÇ
‚îÇ  ‚Ä¢ Orchestrates multi-step agent workflows                          ‚îÇ
‚îÇ  ‚Ä¢ Delegates memory operations to Brain                             ‚îÇ
‚îÇ  ‚Ä¢ Exposes tools for LLM function calling                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                                     ‚îÇ
                ‚ñº                                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      ContextBrain         ‚îÇ           ‚îÇ     ContextCommerce       ‚îÇ
‚îÇ  (The "Memory" ‚Äî RAG)     ‚îÇ           ‚îÇ   (The "Store" ‚Äî PIM)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Vector storage          ‚îÇ           ‚îÇ ‚Ä¢ Product catalog         ‚îÇ
‚îÇ ‚Ä¢ Semantic search         ‚îÇ           ‚îÇ ‚Ä¢ Taxonomy management     ‚îÇ
‚îÇ ‚Ä¢ Knowledge graph         ‚îÇ           ‚îÇ ‚Ä¢ Supplier integration    ‚îÇ
‚îÇ ‚Ä¢ Episodic memory         ‚îÇ           ‚îÇ ‚Ä¢ E-commerce backend      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚ñ≤                                     ‚ñ≤
                ‚îÇ                                     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ      ContextWorker        ‚îÇ
                    ‚îÇ  (The "Hands" ‚Äî Tasks)    ‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ ‚Ä¢ Temporal workflows      ‚îÇ
                    ‚îÇ ‚Ä¢ Background processing   ‚îÇ
                    ‚îÇ ‚Ä¢ Scheduled jobs          ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Service | Role | How Router Uses It |
|---------|------|-------------------|
| **ContextCore** | Shared types, ContextUnit, gRPC contracts | Types, tokens, protos |
| **ContextBrain** | Knowledge storage and RAG | Search, memory, taxonomy via gRPC |
| **ContextWorker** | Background task execution | Triggers workflows via Temporal |
| **ContextCommerce** | E-commerce platform | Products, enrichment, matching |

> **What is gRPC?** [gRPC](https://grpc.io/) is a high-performance RPC framework that uses Protocol Buffers for serialization. It enables type-safe, efficient communication between services ‚Äî faster than REST, with built-in streaming support.

### Memory & Retrieval (The Brain)

ContextRouter delegates all memory operations to **ContextBrain** via the `BrainProvider`:

```python
from contextrouter.modules.providers.storage import BrainProvider

brain = BrainProvider(config)
results = await brain.search("product taxonomy", limit=10)
```

Set your mode via `BRAIN_MODE=local` or `BRAIN_MODE=grpc`.

## Key Features

- **üß© Modular Architecture** ‚Äî swap components without changing agent logic
- **üéØ Agent Orchestration** ‚Äî LangGraph state machines for complex workflows
- **üõ°Ô∏è Production Ready** ‚Äî ContextUnit protocol for data provenance and audit trails
- **üåê Universal Model Support** ‚Äî 15+ LLM providers with automatic fallback
- **‚ö° Reliability** ‚Äî quota exhaustion, rate limit, and timeout handling
- **üîß Extensible** ‚Äî add providers, graphs, tools via registry pattern

## Supported LLM Providers

| Provider | Key | Use Case |
|----------|-----|----------|
| **Vertex AI** | `vertex/gemini-2.0-flash` | Production, multimodal |
| **OpenAI** | `openai/gpt-5-mini` | General purpose |
| **Anthropic** | `anthropic/claude-sonnet-4` | Reasoning, analysis |
| **Perplexity** | `perplexity/sonar` | Web-grounded search |
| **Groq** | `groq/llama-3.3-70b-versatile` | Ultra-fast inference |
| **OpenRouter** | `openrouter/deepseek/deepseek-r1` | Access to 100+ models |
| **Local** | `local/llama3.2` | Privacy, development |
| **RLM** | `rlm/gpt-5-mini` | Massive context (50k+ items) |

## Quick Start

```python
from contextrouter.cortex import stream_agent

async for event in stream_agent(
    messages=[{"role": "user", "content": "How does RAG work?"}],
    session_id="session_123",
    platform="web",
):
    print(event)
```

## Installation

```bash
pip install contextrouter

# With all providers (recommended):
pip install contextrouter[vertex,storage,ingestion]

# Observability (optional):
pip install contextrouter[observability]
```

## Configuration

```bash
# LLM routing
export CONTEXTROUTER_DEFAULT_LLM="openai/gpt-5-mini"
export CONTEXTROUTER_FALLBACK_LLMS="anthropic/claude-sonnet-4,vertex/gemini-2.0-flash"

# Brain connection
export BRAIN_MODE="grpc"
export BRAIN_GRPC_HOST="localhost:50051"

# LLM providers
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="..."
export GOOGLE_CLOUD_PROJECT="my-project"
export PERPLEXITY_API_KEY="pplx-..."
```

## Documentation

- [Full Documentation](https://contextrouter.dev) ‚Äî complete guides and API reference
- [Technical Reference](./contextrouter-fulldoc.md) ‚Äî architecture deep-dive
- [Contributing Guide](./CONTRIBUTING.md) ‚Äî Golden Paths for adding functionality

## Contributing

We welcome contributions! See our [Contributing Guide](./CONTRIBUTING.md) for:

- **Golden Path: Adding LLM Providers** ‚Äî full template with error handling
- **Golden Path: Adding Config Sections** ‚Äî Pydantic settings pattern
- **Golden Path: Adding Cortex Graphs** ‚Äî LangGraph agent workflows
- **Golden Path: Adding Tools** ‚Äî LLM function calling

## License

This project is licensed under the terms specified in [LICENSE.md](LICENSE.md).
